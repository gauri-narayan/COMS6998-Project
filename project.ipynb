{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT-BASED STOCK MARKET PREDICTION\n",
    "By Gauri Narayan & Raefah Wahid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import json\n",
    "from statistics import mean\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, date\n",
    "import torch\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Stock market prediction is widely known as a difficult and challenging task, in part due to the volatile and variable nature of the market itself. The Efficient Market Hypothesis (EMH) proposes that the stock market is primarily affected by new information, such as textual data in the form of news or tweets, rather than technical indicators that rely on past information (Bollen et al., 2011). Following this line of thought, researchers have explored different Natural Language Processing techniques when working with textual information as well as experimented with different prediction models. Our goal for this project is to evaluate the different models that can be used to tackle the problem of stock market prediction. We will begin with a simple Naive Bayes model for sentiment prediction as a baseline, and then follow it with a continuous Dirichlet Process Mixture Model for topic-based sentiment prediction. We will then use Vector Autoregression to evaluate how well these models’ outputs work in forecasting stock market closing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We narrowed the focus of this project to ten companies, five of which have a relatively heavy social media presence and five of which do not: Amazon, Apple, Microsoft, Disney, Google, CVS, General Electric, Santander, Goldman Sachs, China Construction Bank. We scraped tweets for each company by using the company’s common name as a keyword. Ten tweets were gathered per day for each company over the year 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "companies = [('AMZN', 'Amazon'), ('AAPL', 'Apple'), ('MSFT', 'Microsoft'),\n",
    "             ('DIS', 'Disney'), ('GOOG', 'Google'), ('CVS', 'CVS'),\n",
    "             ('GE', 'General Electric'), ('SAN', 'Santander'),\n",
    "             ('GS', 'Goldman Sachs'), ('CICHY', 'China Construction Bank')]\n",
    "stock_data = []\n",
    "tweet_data = []\n",
    "tweets = []\n",
    "n = 1  # usually this would be equal to len(companies), but due to the long runtime this report uses a demo (i.e., just Amazon)\n",
    "for company in companies:\n",
    "    abbr = company[0]\n",
    "    tweet = pd.read_csv('./tweets/' + abbr + '_tweets.csv')\n",
    "    del tweet['Unnamed: 0']\n",
    "    tweets.append(tweet)\n",
    "    curr_stock = pd.read_csv('./financial/' + abbr + '_financial.csv')\n",
    "    del curr_stock['Unnamed: 0']\n",
    "    stock_data.append(curr_stock)\n",
    "    curr_tweet = pd.read_csv('./sentiment/' + abbr + '_sentiment.csv')\n",
    "    times = []\n",
    "    for time in curr_tweet['Time']:\n",
    "        date = time.split()[0]\n",
    "        times.append(date)\n",
    "    curr_tweet['Time'] = times\n",
    "    del curr_tweet['Unnamed: 0']\n",
    "    del curr_tweet['Unnamed: 0.1']\n",
    "    tweet_data.append(curr_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:59:56+00:00</td>\n",
       "      <td>dang amazon. i talking customer service the ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-25 17:06:25+00:00</td>\n",
       "      <td>learn the new cloud like way manage premise da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 23:59:53+00:00</td>\n",
       "      <td>chacousa amazonpay i ordered pair chaco’s sund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 23:59:43+00:00</td>\n",
       "      <td>check loiygit amazon music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 23:59:41+00:00</td>\n",
       "      <td>head banging doll [clean] kakicchysmusic mp do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Time  \\\n",
       "0  2018-12-31 23:59:56+00:00   \n",
       "1  2020-11-25 17:06:25+00:00   \n",
       "2  2018-12-31 23:59:53+00:00   \n",
       "3  2018-12-31 23:59:43+00:00   \n",
       "4  2018-12-31 23:59:41+00:00   \n",
       "\n",
       "                                                Text  \n",
       "0  dang amazon. i talking customer service the ph...  \n",
       "1  learn the new cloud like way manage premise da...  \n",
       "2  chacousa amazonpay i ordered pair chaco’s sund...  \n",
       "3                         check loiygit amazon music  \n",
       "4  head banging doll [clean] kakicchysmusic mp do...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0].head()  # sample tweet data for Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1510.800049</td>\n",
       "      <td>1520.760010</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1501.969971</td>\n",
       "      <td>1501.969971</td>\n",
       "      <td>6954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1465.199951</td>\n",
       "      <td>1553.359985</td>\n",
       "      <td>1460.930054</td>\n",
       "      <td>1539.130005</td>\n",
       "      <td>1539.130005</td>\n",
       "      <td>7983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1520.010010</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>1497.109985</td>\n",
       "      <td>1500.280029</td>\n",
       "      <td>1500.280029</td>\n",
       "      <td>6975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1530.000000</td>\n",
       "      <td>1594.000000</td>\n",
       "      <td>1518.310059</td>\n",
       "      <td>1575.390015</td>\n",
       "      <td>1575.390015</td>\n",
       "      <td>9182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1602.310059</td>\n",
       "      <td>1634.560059</td>\n",
       "      <td>1589.189941</td>\n",
       "      <td>1629.510010</td>\n",
       "      <td>1629.510010</td>\n",
       "      <td>7993200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2018-12-31  1510.800049  1520.760010  1487.000000  1501.969971   \n",
       "1  2019-01-02  1465.199951  1553.359985  1460.930054  1539.130005   \n",
       "2  2019-01-03  1520.010010  1538.000000  1497.109985  1500.280029   \n",
       "3  2019-01-04  1530.000000  1594.000000  1518.310059  1575.390015   \n",
       "4  2019-01-07  1602.310059  1634.560059  1589.189941  1629.510010   \n",
       "\n",
       "     Adj Close   Volume  \n",
       "0  1501.969971  6954500  \n",
       "1  1539.130005  7983100  \n",
       "2  1500.280029  6975600  \n",
       "3  1575.390015  9182600  \n",
       "4  1629.510010  7993200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data[0].head()  # sample stock data for Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "The dataset of tweets were cleaned as they were scraped. The standard techniques of removing digits, punctuation, symbols, and stopwords were applied. For ease of analysis, we dealt only with tweets written in English. As a baseline for sentiment analysis, we began by implementing the Naive Bayes model. Though Naive Bayes assumes independence, it is a standard approach to text classification and a good way to test the performance of our forecasting model later on. The Naive Bayes model implemented assigns a positive and negative sentiment score to each tweet using the formula\n",
    "\n",
    "$$\\hat{y} = \\frac{p(S_k) \\cdot \\prod_{i=1}^n p(x_i \\mid S_k)}{\\prod_{i=1}^n p(x_i)},$$\n",
    "\n",
    "where $\\hat{y}$ is the resulting sentiment score, $S_k$ is one of two sentiment labels (positive or negative), and $x_i$ is a particular word in the tweet. To train this model, we used a public dataset [LINK?] of standard positive and negative tweets that were already labelled. After computing prior probabilities based on this training data, we created a Naive Bayes model that read in tweets related to our chosen companies and computed those tweets’ likelihoods and resulting log sentiment scores. Due to the fact that some of the companies are not particularly well-known on Twitter, some days produced no tweets that mentioned the company; for these instances, a sentiment value of 0 was assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>dang amazon. i talking customer service the ph...</td>\n",
       "      <td>[66.97592609158492, 71.83459462136356, 5.00994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>learn the new cloud like way manage premise da...</td>\n",
       "      <td>[63.96525067459205, 83.39114379494283, 3.53773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>chacousa amazonpay i ordered pair chaco’s sund...</td>\n",
       "      <td>[65.3480030078838, 40.37738505535857, -8.38073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>check loiygit amazon music</td>\n",
       "      <td>[8.873573528973495, 6.795776260509992, -11.449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>head banging doll [clean] kakicchysmusic mp do...</td>\n",
       "      <td>[33.08781006722295, 15.435225146842129, 11.620...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                               Text  \\\n",
       "0  2018-12-31  dang amazon. i talking customer service the ph...   \n",
       "1  2020-11-25  learn the new cloud like way manage premise da...   \n",
       "2  2018-12-31  chacousa amazonpay i ordered pair chaco’s sund...   \n",
       "3  2018-12-31                         check loiygit amazon music   \n",
       "4  2018-12-31  head banging doll [clean] kakicchysmusic mp do...   \n",
       "\n",
       "                                           Sentiment  \n",
       "0  [66.97592609158492, 71.83459462136356, 5.00994...  \n",
       "1  [63.96525067459205, 83.39114379494283, 3.53773...  \n",
       "2  [65.3480030078838, 40.37738505535857, -8.38073...  \n",
       "3  [8.873573528973495, 6.795776260509992, -11.449...  \n",
       "4  [33.08781006722295, 15.435225146842129, 11.620...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample sentiment data for Amazon; the first index in the sentiment is positive, the second negative\n",
    "tweet_data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output for each tweet is an array of length two, with the positive score in the first position and the negative score in the second. Instead of classifying any particular tweet into a final category of positive or negative, we kept these scores so that we could average together the relative positive or negative sentiment for a particular company across a day. Thus, we can see compare the effect of positive sentiment against negative sentiment when it comes to stock price forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autoregression\n",
    "Vector Autoregression (VAR) is often used for time series dependent forecasting due to the fact it models time series as a linear combination of their past values and the values of other time series. Since our stock information only deals with end-of-day results, we averaged the sentiment scores for tweets across each day for each company. With a lag of 1, our model was formatted as the following linear regression\n",
    "\n",
    "$$y_t = \\theta_1 x_{t- \\text{lag}} + \\theta_2 y_{t - \\text{lag}} + b,$$\n",
    "\n",
    "where $y_t$ is the closing price of the current day’s stock, $x_{t- \\text{lag}}$ is the previous day’s average positive or negative sentiment, $y_{t - \\text{lag}}$ is the previous day’s closing price, $\\theta_1$ and $\\theta_2$ are weights, and $b$ is the bias.\n",
    "\n",
    "To implement this, we used Pyro’s linear regression module. We use a mean squared error (MSE) loss and optimized using Adam. We began with a lag = 1 using positive sentiment first, and then negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting lagged data\n",
    "## running VAR (looking at loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the highly dynamic nature of both sentiment and the stock market, forecasting with a lag of more than seven days is unlikely to be effective. We began with a lag = 1, as seen above, but we experimented with a lag = 3 and 5 as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lag of 3 and 4\n",
    "## running VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that though the loss decreases further with a lag = 3, it does not improve much more than that with a lag = 5. A lag = 3 would be the most optimal, though its performance is only marginally better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "## Granger Causality\n",
    "///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run GC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Mean Squared Error\n",
    "To evaluate our model, we utilized MSE as a metric. For each company’s dataset, we split the data into a training and testing set, with 80% of the original data in the training set and 20% in the testing set. We ran VAR on the training set to retrieve an appropriate set of weights and bias for each company. We used this output to predict the closing prices of the testing set, which yielded the following MSE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Continuous Dirichlet Process Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explanation + running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Var on DPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inference and evaluation on DPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
