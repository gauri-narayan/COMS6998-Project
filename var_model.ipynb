{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import json\n",
    "from statistics import mean\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, date\n",
    "import torch\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "sample_stock = pd.read_csv('COMS6998-Project/financial/AMZN_financial.csv')\n",
    "sample_tweet = pd.read_csv('COMS6998-Project/sentiments/Amazon_tweet_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1510.800049</td>\n",
       "      <td>1520.760010</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1501.969971</td>\n",
       "      <td>1501.969971</td>\n",
       "      <td>6954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1465.199951</td>\n",
       "      <td>1553.359985</td>\n",
       "      <td>1460.930054</td>\n",
       "      <td>1539.130005</td>\n",
       "      <td>1539.130005</td>\n",
       "      <td>7983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1520.010010</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>1497.109985</td>\n",
       "      <td>1500.280029</td>\n",
       "      <td>1500.280029</td>\n",
       "      <td>6975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1530.000000</td>\n",
       "      <td>1594.000000</td>\n",
       "      <td>1518.310059</td>\n",
       "      <td>1575.390015</td>\n",
       "      <td>1575.390015</td>\n",
       "      <td>9182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1602.310059</td>\n",
       "      <td>1634.560059</td>\n",
       "      <td>1589.189941</td>\n",
       "      <td>1629.510010</td>\n",
       "      <td>1629.510010</td>\n",
       "      <td>7993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1664.689941</td>\n",
       "      <td>1676.609985</td>\n",
       "      <td>1616.609985</td>\n",
       "      <td>1656.579956</td>\n",
       "      <td>1656.579956</td>\n",
       "      <td>8881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>1652.979980</td>\n",
       "      <td>1667.800049</td>\n",
       "      <td>1641.400024</td>\n",
       "      <td>1659.420044</td>\n",
       "      <td>1659.420044</td>\n",
       "      <td>6348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>1641.010010</td>\n",
       "      <td>1663.250000</td>\n",
       "      <td>1621.619995</td>\n",
       "      <td>1656.219971</td>\n",
       "      <td>1656.219971</td>\n",
       "      <td>6507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>1640.550049</td>\n",
       "      <td>1660.290039</td>\n",
       "      <td>1636.219971</td>\n",
       "      <td>1640.560059</td>\n",
       "      <td>1640.560059</td>\n",
       "      <td>4686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>1615.000000</td>\n",
       "      <td>1648.199951</td>\n",
       "      <td>1595.150024</td>\n",
       "      <td>1617.209961</td>\n",
       "      <td>1617.209961</td>\n",
       "      <td>6005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1675.160034</td>\n",
       "      <td>1626.010010</td>\n",
       "      <td>1674.560059</td>\n",
       "      <td>1674.560059</td>\n",
       "      <td>5998500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>1684.219971</td>\n",
       "      <td>1705.000000</td>\n",
       "      <td>1675.880005</td>\n",
       "      <td>1683.780029</td>\n",
       "      <td>1683.780029</td>\n",
       "      <td>6366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>1700.170044</td>\n",
       "      <td>1677.500000</td>\n",
       "      <td>1693.219971</td>\n",
       "      <td>1693.219971</td>\n",
       "      <td>4208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>1712.000000</td>\n",
       "      <td>1716.199951</td>\n",
       "      <td>1691.540039</td>\n",
       "      <td>1696.199951</td>\n",
       "      <td>1696.199951</td>\n",
       "      <td>6020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>1681.000000</td>\n",
       "      <td>1681.869995</td>\n",
       "      <td>1610.199951</td>\n",
       "      <td>1632.170044</td>\n",
       "      <td>1632.170044</td>\n",
       "      <td>6416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>1656.000000</td>\n",
       "      <td>1657.430054</td>\n",
       "      <td>1612.000000</td>\n",
       "      <td>1640.020020</td>\n",
       "      <td>1640.020020</td>\n",
       "      <td>5225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>1641.069946</td>\n",
       "      <td>1657.260010</td>\n",
       "      <td>1631.780029</td>\n",
       "      <td>1654.930054</td>\n",
       "      <td>1654.930054</td>\n",
       "      <td>4089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>1670.500000</td>\n",
       "      <td>1683.479980</td>\n",
       "      <td>1661.609985</td>\n",
       "      <td>1670.569946</td>\n",
       "      <td>1670.569946</td>\n",
       "      <td>4945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>1643.589966</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>1614.089966</td>\n",
       "      <td>1637.890015</td>\n",
       "      <td>1637.890015</td>\n",
       "      <td>4837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>1631.270020</td>\n",
       "      <td>1632.380005</td>\n",
       "      <td>1590.719971</td>\n",
       "      <td>1593.880005</td>\n",
       "      <td>1593.880005</td>\n",
       "      <td>4632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>1623.000000</td>\n",
       "      <td>1676.949951</td>\n",
       "      <td>1619.680054</td>\n",
       "      <td>1670.430054</td>\n",
       "      <td>1670.430054</td>\n",
       "      <td>5783800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>1692.849976</td>\n",
       "      <td>1736.410034</td>\n",
       "      <td>1679.079956</td>\n",
       "      <td>1718.729980</td>\n",
       "      <td>1718.729980</td>\n",
       "      <td>10910300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        Date         Open         High          Low  \\\n",
       "0            0  2018-12-31  1510.800049  1520.760010  1487.000000   \n",
       "1            1  2019-01-02  1465.199951  1553.359985  1460.930054   \n",
       "2            2  2019-01-03  1520.010010  1538.000000  1497.109985   \n",
       "3            3  2019-01-04  1530.000000  1594.000000  1518.310059   \n",
       "4            4  2019-01-07  1602.310059  1634.560059  1589.189941   \n",
       "5            5  2019-01-08  1664.689941  1676.609985  1616.609985   \n",
       "6            6  2019-01-09  1652.979980  1667.800049  1641.400024   \n",
       "7            7  2019-01-10  1641.010010  1663.250000  1621.619995   \n",
       "8            8  2019-01-11  1640.550049  1660.290039  1636.219971   \n",
       "9            9  2019-01-14  1615.000000  1648.199951  1595.150024   \n",
       "10          10  2019-01-15  1632.000000  1675.160034  1626.010010   \n",
       "11          11  2019-01-16  1684.219971  1705.000000  1675.880005   \n",
       "12          12  2019-01-17  1680.000000  1700.170044  1677.500000   \n",
       "13          13  2019-01-18  1712.000000  1716.199951  1691.540039   \n",
       "14          14  2019-01-22  1681.000000  1681.869995  1610.199951   \n",
       "15          15  2019-01-23  1656.000000  1657.430054  1612.000000   \n",
       "16          16  2019-01-24  1641.069946  1657.260010  1631.780029   \n",
       "17          17  2019-01-25  1670.500000  1683.479980  1661.609985   \n",
       "18          18  2019-01-28  1643.589966  1645.000000  1614.089966   \n",
       "19          19  2019-01-29  1631.270020  1632.380005  1590.719971   \n",
       "20          20  2019-01-30  1623.000000  1676.949951  1619.680054   \n",
       "21          21  2019-01-31  1692.849976  1736.410034  1679.079956   \n",
       "\n",
       "          Close    Adj Close    Volume  \n",
       "0   1501.969971  1501.969971   6954500  \n",
       "1   1539.130005  1539.130005   7983100  \n",
       "2   1500.280029  1500.280029   6975600  \n",
       "3   1575.390015  1575.390015   9182600  \n",
       "4   1629.510010  1629.510010   7993200  \n",
       "5   1656.579956  1656.579956   8881400  \n",
       "6   1659.420044  1659.420044   6348800  \n",
       "7   1656.219971  1656.219971   6507700  \n",
       "8   1640.560059  1640.560059   4686200  \n",
       "9   1617.209961  1617.209961   6005900  \n",
       "10  1674.560059  1674.560059   5998500  \n",
       "11  1683.780029  1683.780029   6366900  \n",
       "12  1693.219971  1693.219971   4208900  \n",
       "13  1696.199951  1696.199951   6020500  \n",
       "14  1632.170044  1632.170044   6416800  \n",
       "15  1640.020020  1640.020020   5225200  \n",
       "16  1654.930054  1654.930054   4089900  \n",
       "17  1670.569946  1670.569946   4945900  \n",
       "18  1637.890015  1637.890015   4837700  \n",
       "19  1593.880005  1593.880005   4632800  \n",
       "20  1670.430054  1670.430054   5783800  \n",
       "21  1718.729980  1718.729980  10910300  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "january = sample_stock[:22][:]\n",
    "january"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for time in sample_tweet['Time']:\n",
    "    date = time.split()[0]\n",
    "    times.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>how train amazon’s alexa recognize different p...</td>\n",
       "      <td>[25.824289998295193, -3.393862700085713, -10.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>our best selling fire tv alexa. starting .</td>\n",
       "      <td>[18.373346870949714, -3.6249137586891753, -11....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>dantwitwit freetotweet torontostar ddale colle...</td>\n",
       "      <td>[97.8097246096391, 105.56702201940892, -5.9932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>cosmic carol well done have read amazon got co...</td>\n",
       "      <td>[41.73129325240489, 30.821970932232297, -10.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>fat sushi roll amazonhelp newegg yikes. amazon...</td>\n",
       "      <td>[50.74213731507144, 31.57358307433904, -10.536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1525</td>\n",
       "      <td>1525</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>amazon , i considering cancel credit card futu...</td>\n",
       "      <td>[25.449361421899287, 3.7985175769405113, -13.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>love ... new amazon review my book, jesus econ...</td>\n",
       "      <td>[69.24814373571483, 46.21258844375352, 1.73503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>my amazon merch account got shut dow two desig...</td>\n",
       "      <td>[32.12811082733438, -1.6580737853152958, -10.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1528</td>\n",
       "      <td>1528</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>teamtforce customer service absolutely abhorre...</td>\n",
       "      <td>[56.3848338674943, 34.02731093082885, -8.43321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1529</td>\n",
       "      <td>1529</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>. hnewsource giving away amazon us gift card t...</td>\n",
       "      <td>[8.441502983920461, 21.098035817503096, 0.4615...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1530 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1        Time  \\\n",
       "0              0             0  2019-01-01   \n",
       "1              1             1  2020-11-10   \n",
       "2              2             2  2019-01-01   \n",
       "3              3             3  2019-01-01   \n",
       "4              4             4  2019-01-01   \n",
       "...          ...           ...         ...   \n",
       "1525        1525          1525  2019-01-30   \n",
       "1526        1526          1526  2019-01-30   \n",
       "1527        1527          1527  2019-01-30   \n",
       "1528        1528          1528  2019-01-30   \n",
       "1529        1529          1529  2019-01-30   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     how train amazon’s alexa recognize different p...   \n",
       "1            our best selling fire tv alexa. starting .   \n",
       "2     dantwitwit freetotweet torontostar ddale colle...   \n",
       "3     cosmic carol well done have read amazon got co...   \n",
       "4     fat sushi roll amazonhelp newegg yikes. amazon...   \n",
       "...                                                 ...   \n",
       "1525  amazon , i considering cancel credit card futu...   \n",
       "1526  love ... new amazon review my book, jesus econ...   \n",
       "1527  my amazon merch account got shut dow two desig...   \n",
       "1528  teamtforce customer service absolutely abhorre...   \n",
       "1529  . hnewsource giving away amazon us gift card t...   \n",
       "\n",
       "                                              Sentiment  \n",
       "0     [25.824289998295193, -3.393862700085713, -10.6...  \n",
       "1     [18.373346870949714, -3.6249137586891753, -11....  \n",
       "2     [97.8097246096391, 105.56702201940892, -5.9932...  \n",
       "3     [41.73129325240489, 30.821970932232297, -10.08...  \n",
       "4     [50.74213731507144, 31.57358307433904, -10.536...  \n",
       "...                                                 ...  \n",
       "1525  [25.449361421899287, 3.7985175769405113, -13.9...  \n",
       "1526  [69.24814373571483, 46.21258844375352, 1.73503...  \n",
       "1527  [32.12811082733438, -1.6580737853152958, -10.6...  \n",
       "1528  [56.3848338674943, 34.02731093082885, -8.43321...  \n",
       "1529  [8.441502983920461, 21.098035817503096, 0.4615...  \n",
       "\n",
       "[1530 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweet['Time'] = times\n",
    "sample_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_lag(stocks, tweets):\n",
    "    prev_stock_close = []\n",
    "    curr_stock_close = []\n",
    "    avg_pos = []\n",
    "    avg_neg = []\n",
    "\n",
    "    prev_time = datetime.strptime(tweets['Time'][0], '%Y-%m-%d')\n",
    "    curr_time = None\n",
    "    for date in stocks['Date']:\n",
    "        if date == stocks['Date'][0]:\n",
    "            continue\n",
    "        index = stocks[stocks['Date'] == date].index[0] # getting current date's index in series\n",
    "        prev_stock_close.append(stocks['Close'][index-1]) # lag = 1\n",
    "        curr_stock_close.append(stocks['Close'][index])\n",
    "        pos = []\n",
    "        neg = []\n",
    "        for time in tweets['Time']:\n",
    "            start = datetime.strptime(copy.copy(time), '%Y-%m-%d')\n",
    "            curr_time = datetime.strptime(date, '%Y-%m-%d')\n",
    "            if (start.date() >= prev_time.date()) and (start.date() < curr_time.date()):\n",
    "                index = tweets[tweets['Time'] == time].index[0]\n",
    "                pos.append(json.loads(tweets['Sentiment'][index])[0])\n",
    "                neg.append(json.loads(tweets['Sentiment'][index])[1])\n",
    "        avg_pos.append(mean(pos))\n",
    "        avg_neg.append(mean(neg))\n",
    "        prev_time = copy.copy(curr_time)\n",
    "    \n",
    "    return prev_stock_close, curr_stock_close, avg_pos, avg_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_lag(stocks, tweets, lag):\n",
    "    prev_stock_close = []\n",
    "    curr_stock_close = []\n",
    "    avg_pos = []\n",
    "    avg_neg = []\n",
    "\n",
    "    prev_time = datetime.strptime(tweets['Time'][0], '%Y-%m-%d')\n",
    "    curr_time = None\n",
    "    for date in stocks['Date']:\n",
    "        if datetime.strptime(date, '%Y-%m-%d').date() < datetime.strptime(stocks['Date'][lag], '%Y-%m-%d').date():\n",
    "            continue\n",
    "        index = stocks[stocks['Date'] == date].index[0] # getting current date's index in series\n",
    "        prev_stock_close.append(stocks['Close'][index-lag])\n",
    "        curr_stock_close.append(stocks['Close'][index])\n",
    "        pos = []\n",
    "        neg = []\n",
    "        for time in tweets['Time']:\n",
    "            start = datetime.strptime(copy.copy(time), '%Y-%m-%d')\n",
    "            curr_time = datetime.strptime(date, '%Y-%m-%d')\n",
    "            next_day = prev_time + timedelta(days = 1) \n",
    "            if (start.date() >= prev_time.date()) and (start.date() < next_day.date()):\n",
    "                index = tweets[tweets['Time'] == time].index[0]\n",
    "                pos.append(json.loads(tweets['Sentiment'][index])[0])\n",
    "                neg.append(json.loads(tweets['Sentiment'][index])[1])\n",
    "        avg_pos.append(mean(pos))\n",
    "        avg_neg.append(mean(neg))\n",
    "        prev_time = copy.copy(curr_time)\n",
    "    \n",
    "    return prev_stock_close, curr_stock_close, avg_pos, avg_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_stock_close, curr_stock_close, avg_pos, avg_neg = multi_lag(january, sample_tweet, 5)\n",
    "data = {'curr_close': curr_stock_close,\n",
    "        'prev_close': prev_stock_close,\n",
    "        'pos_sentiment': avg_pos,\n",
    "        'neg_sentiment': avg_neg}\n",
    "df = pd.DataFrame(data, columns = ['curr_close','prev_close', 'pos_sentiment', 'neg_sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_close</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539.130005</td>\n",
       "      <td>1501.969971</td>\n",
       "      <td>25.824290</td>\n",
       "      <td>-3.393863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500.280029</td>\n",
       "      <td>1539.130005</td>\n",
       "      <td>138.404674</td>\n",
       "      <td>97.169707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1575.390015</td>\n",
       "      <td>1500.280029</td>\n",
       "      <td>98.321253</td>\n",
       "      <td>90.279607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1629.510010</td>\n",
       "      <td>1575.390015</td>\n",
       "      <td>55.811772</td>\n",
       "      <td>41.735355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1656.579956</td>\n",
       "      <td>1629.510010</td>\n",
       "      <td>29.608060</td>\n",
       "      <td>21.908681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1659.420044</td>\n",
       "      <td>1656.579956</td>\n",
       "      <td>42.887675</td>\n",
       "      <td>32.379150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1656.219971</td>\n",
       "      <td>1659.420044</td>\n",
       "      <td>74.385061</td>\n",
       "      <td>60.598953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1640.560059</td>\n",
       "      <td>1656.219971</td>\n",
       "      <td>18.517423</td>\n",
       "      <td>9.034163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1617.209961</td>\n",
       "      <td>1640.560059</td>\n",
       "      <td>29.640189</td>\n",
       "      <td>15.669504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1674.560059</td>\n",
       "      <td>1617.209961</td>\n",
       "      <td>10.022896</td>\n",
       "      <td>-0.132795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1683.780029</td>\n",
       "      <td>1674.560059</td>\n",
       "      <td>32.123542</td>\n",
       "      <td>12.296627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1693.219971</td>\n",
       "      <td>1683.780029</td>\n",
       "      <td>10.022896</td>\n",
       "      <td>-0.132795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1696.199951</td>\n",
       "      <td>1693.219971</td>\n",
       "      <td>8.958753</td>\n",
       "      <td>-1.144307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1632.170044</td>\n",
       "      <td>1696.199951</td>\n",
       "      <td>40.662883</td>\n",
       "      <td>27.985563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1640.020020</td>\n",
       "      <td>1632.170044</td>\n",
       "      <td>45.721065</td>\n",
       "      <td>35.978944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1654.930054</td>\n",
       "      <td>1640.020020</td>\n",
       "      <td>40.016518</td>\n",
       "      <td>19.227256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1670.569946</td>\n",
       "      <td>1654.930054</td>\n",
       "      <td>5.471482</td>\n",
       "      <td>-1.298622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1637.890015</td>\n",
       "      <td>1670.569946</td>\n",
       "      <td>47.800202</td>\n",
       "      <td>41.298692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1593.880005</td>\n",
       "      <td>1637.890015</td>\n",
       "      <td>40.620854</td>\n",
       "      <td>0.977406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1670.430054</td>\n",
       "      <td>1593.880005</td>\n",
       "      <td>30.366806</td>\n",
       "      <td>21.938006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1718.729980</td>\n",
       "      <td>1670.430054</td>\n",
       "      <td>28.054377</td>\n",
       "      <td>13.145495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     curr_close   prev_close  pos_sentiment  neg_sentiment\n",
       "0   1539.130005  1501.969971      25.824290      -3.393863\n",
       "1   1500.280029  1539.130005     138.404674      97.169707\n",
       "2   1575.390015  1500.280029      98.321253      90.279607\n",
       "3   1629.510010  1575.390015      55.811772      41.735355\n",
       "4   1656.579956  1629.510010      29.608060      21.908681\n",
       "5   1659.420044  1656.579956      42.887675      32.379150\n",
       "6   1656.219971  1659.420044      74.385061      60.598953\n",
       "7   1640.560059  1656.219971      18.517423       9.034163\n",
       "8   1617.209961  1640.560059      29.640189      15.669504\n",
       "9   1674.560059  1617.209961      10.022896      -0.132795\n",
       "10  1683.780029  1674.560059      32.123542      12.296627\n",
       "11  1693.219971  1683.780029      10.022896      -0.132795\n",
       "12  1696.199951  1693.219971       8.958753      -1.144307\n",
       "13  1632.170044  1696.199951      40.662883      27.985563\n",
       "14  1640.020020  1632.170044      45.721065      35.978944\n",
       "15  1654.930054  1640.020020      40.016518      19.227256\n",
       "16  1670.569946  1654.930054       5.471482      -1.298622\n",
       "17  1637.890015  1670.569946      47.800202      41.298692\n",
       "18  1593.880005  1637.890015      40.620854       0.977406\n",
       "19  1670.430054  1593.880005      30.366806      21.938006\n",
       "20  1718.729980  1670.430054      28.054377      13.145495"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gauri --> after cDPM: with topics, it would be current day close, prev day close, prev day topic (?)\n",
    "\n",
    "prev_stock_close, curr_stock_close, avg_pos, avg_neg = uni_lag(january, sample_tweet)\n",
    "data = {'curr_close': curr_stock_close,\n",
    "        'prev_close': prev_stock_close,\n",
    "        'pos_sentiment': avg_pos,\n",
    "        'neg_sentiment': avg_neg}\n",
    "df = pd.DataFrame(data, columns = ['curr_close','prev_close', 'pos_sentiment', 'neg_sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(sample_stock['Date'], sample_stock['Close'], \"o\")\n",
    "ax.set(xlabel='Date',\n",
    "          ylabel='Closing Price',\n",
    "          title='HK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformatting data for VAR model\n",
    "y = torch.tensor(df['curr_close'].values, dtype=torch.float)\n",
    "pos_x = torch.tensor(df[['prev_close', 'pos_sentiment']].values, dtype=torch.float)\n",
    "neg_x = torch.tensor(df[['prev_close', 'neg_sentiment']].values, dtype=torch.float)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_model(x, y):\n",
    "    # Regression model\n",
    "    linear_reg_model = PyroModule[nn.Linear](2, 1)\n",
    "\n",
    "    # Define loss and optimize\n",
    "    loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "    num_iterations = 1500\n",
    "    \n",
    "    def train():\n",
    "        # run the model forward on the data\n",
    "        y_pred = linear_reg_model(x).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        return loss\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        loss = train()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in linear_reg_model.named_parameters():\n",
    "        print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model(pos_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model(neg_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one equation for each company (with pos + neg sentiment)\n",
    "# experiment with lag = 1, 3, 5 days\n",
    "# one equation for each topic in each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=7.0507  , p=0.0167  , df_denom=17, df_num=1\n",
      "ssr based chi2 test:   chi2=8.2950  , p=0.0040  , df=1\n",
      "likelihood ratio test: chi2=6.9390  , p=0.0084  , df=1\n",
      "parameter F test:         F=7.0507  , p=0.0167  , df_denom=17, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.9144  , p=0.1844  , df_denom=17, df_num=1\n",
      "ssr based chi2 test:   chi2=2.2523  , p=0.1334  , df=1\n",
      "likelihood ratio test: chi2=2.1342  , p=0.1440  , df=1\n",
      "parameter F test:         F=1.9144  , p=0.1844  , df_denom=17, df_num=1\n"
     ]
    }
   ],
   "source": [
    "# granger causality\n",
    "granger_test_result = grangercausalitytests(df[['prev_close','pos_sentiment']], maxlag=1, verbose=True)\n",
    "granger_test_result = grangercausalitytests(df[['prev_close','neg_sentiment']], maxlag=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro predictive model for evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
